{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks for laboratory assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports section\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract webpage data given the url\n",
    "\n",
    "Create a Python script that performs basic web scraping on a page to extract all the information into text and returns it as a string.\n",
    "String should not contain tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test test\n",
      "test\ttest\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_repetition_of_whitespaces(text: str) -> str:\n",
    "    return re.sub(r\"\\s\\s+\", lambda s: s.string[s.start()], text)\n",
    "\n",
    "print(remove_repetition_of_whitespaces(\"Test    \\n\\ntest\\n\\t\\t test\\t\\n\\n test\"))\n",
    "\n",
    "def remove_repetition_of_whitespaces_decorator(callback: callable):\n",
    "    def result(*args, **kwargs):\n",
    "        return remove_repetition_of_whitespaces(callback(*args, **kwargs))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url: https://fmi.chnu.edu.ua/\n",
      "status code: 200\n",
      "\n",
      "Головна - Факультет математики та інформатики\n",
      "Перейти до основного вмісту\n",
      "[email protected]\n",
      "Новини Україна, м. Чернівці, вул. Університетська, 28\n",
      "Всі\n",
      "Загальні\n",
      "Оголошення\n",
      "Події\n",
      "Студенту\n",
      "Викладачу\n",
      "Вітання\n",
      "Діяльність\n",
      "Наукова\n",
      "Навчально-методична\n",
      "Міжна\n",
      "url: https://en.wikipedia.org/wiki/Web_scraping\n",
      "status code: 200\n",
      "\n",
      "Web scraping - Wikipedia\n",
      "Jump to content\n",
      "Main menu\n",
      "Main menu\n",
      "move to sidebar\n",
      "hide\n",
      "Navigation\n",
      "Main pageContentsCurrent eventsRandom articleAbout WikipediaContact usDonate\n",
      "Contribute\n",
      "HelpLearn to editCommunity portalRecent changesUpload file\n",
      "Search\n",
      "Search\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@remove_repetition_of_whitespaces_decorator\n",
    "def parse_web_page(url):\n",
    "    \"\"\"\n",
    "    Fetch the content of the given web page.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the web page to fetch.\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the page as a string.\n",
    "\n",
    "    Raises:\n",
    "        HTTPError: If the HTTP request returned an unsuccessful status code.\n",
    "    \"\"\"\n",
    "    print(f\"url: {url}\")\n",
    "    response = requests.get(url)\n",
    "    print(f\"status code: {response.status_code}\")\n",
    "    response.raise_for_status()\n",
    "    return BeautifulSoup(response.text).text\n",
    "\n",
    "print(parse_web_page('https://fmi.chnu.edu.ua/')[:255])\n",
    "print(parse_web_page('https://en.wikipedia.org/wiki/Web_scraping')[:255])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from the API\n",
    "\n",
    "Create a python script that performs basic request to API endpoint and saves that data to a JSON file `result.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_api(api_url):\n",
    "    \"\"\"\n",
    "    Fetch the data of the given API endpoint and save it to result.json.\n",
    "\n",
    "    Args:\n",
    "        api_url (str): The URL of the API endpoint.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "\n",
    "    Raises:\n",
    "        HTTPError: If the HTTP request returned an unsuccessful status code.\n",
    "    \"\"\"\n",
    "    return None \n",
    "\n",
    "parse_api('https://api.github.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the json file\n",
    "\n",
    "Parse the `weather.json` file and return weather data for a specific date, that is given as a parameter. Return the data as an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json(date):\n",
    "    \"\"\"\n",
    "    Parse the data from weather.json file and return weather data for a given date.\n",
    "\n",
    "    Args:\n",
    "        date (str): The date for which we look up the weather.\n",
    "\n",
    "    Returns:\n",
    "        list: a list of weather data for a given date.\n",
    "    \"\"\"\n",
    "    return None\n",
    "    \n",
    "target_date = '2024-8-19'\n",
    "print(parse_json(target_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the csv file\n",
    "\n",
    "Parse the `weather.csv` file and return weather data for a specific date, that is given as a parameter. Return the data as an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_csv(date):\n",
    "    \"\"\"\n",
    "    Parse the data from weather.csv file and return weather data for a given date.\n",
    "\n",
    "    Args:\n",
    "        date (str): The date for which we look up the weather.\n",
    "\n",
    "    Returns:\n",
    "        list: a list of weather data for a given date.\n",
    "    \"\"\"\n",
    "    return None\n",
    "    \n",
    "target_date = '1997-5-22'\n",
    "print(parse_csv(target_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data\n",
    "\n",
    "Visualize the `weather.csv` data using matplotlib. Choose your own approach to data visualization. Save the results (as `.png`, `.webp` files etc., your choise) in this repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data():\n",
    "    \"\"\"\n",
    "    Parse the data from weather.csv file and visualize it using Matplotlib. Use more then one visualization. \n",
    "    Save the results in the repository.\n",
    "\n",
    "    Args:\n",
    "        None: None.\n",
    "\n",
    "    Returns:\n",
    "        None: None.\n",
    "    \"\"\"\n",
    "    return None\n",
    "\n",
    "visualize_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
