{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks for laboratory assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports section\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract webpage data given the url\n",
    "\n",
    "Create a Python script that performs basic web scraping on a page to extract all the information into text and returns it as a string.\n",
    "String should not contain tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test test\n",
      "test\ttest\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_repetition_of_whitespaces(text: str) -> str:\n",
    "    return re.sub(r\"\\s\\s+\", lambda s: s.string[s.start()], text)\n",
    "\n",
    "print(remove_repetition_of_whitespaces(\"Test    \\n\\ntest\\n\\t\\t test\\t\\n\\n test\"))\n",
    "\n",
    "def remove_repetition_of_whitespaces_decorator(callback: callable):\n",
    "    def result(*args, **kwargs):\n",
    "        return remove_repetition_of_whitespaces(callback(*args, **kwargs))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url: https://fmi.chnu.edu.ua/\n",
      "status code: 200\n",
      "\n",
      "Головна - Факультет математики та інформатики\n",
      "Перейти до основного вмісту\n",
      "[email protected]\n",
      "Новини Україна, м. Чернівці, вул. Університетська, 28\n",
      "Всі\n",
      "Загальні\n",
      "Оголошення\n",
      "Події\n",
      "Студенту\n",
      "Викладачу\n",
      "Вітання\n",
      "Діяльність\n",
      "Наукова\n",
      "Навчально-методична\n",
      "Міжна\n",
      "url: https://en.wikipedia.org/wiki/Web_scraping\n",
      "status code: 200\n",
      "\n",
      "Web scraping - Wikipedia\n",
      "Jump to content\n",
      "Main menu\n",
      "Main menu\n",
      "move to sidebar\n",
      "hide\n",
      "Navigation\n",
      "Main pageContentsCurrent eventsRandom articleAbout WikipediaContact usDonate\n",
      "Contribute\n",
      "HelpLearn to editCommunity portalRecent changesUpload file\n",
      "Search\n",
      "Search\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@remove_repetition_of_whitespaces_decorator\n",
    "def parse_web_page(url):\n",
    "    \"\"\"\n",
    "    Fetch the content of the given web page.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the web page to fetch.\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the page as a string.\n",
    "\n",
    "    Raises:\n",
    "        HTTPError: If the HTTP request returned an unsuccessful status code.\n",
    "    \"\"\"\n",
    "    print(f\"url: {url}\")\n",
    "    response = requests.get(url)\n",
    "    print(f\"status code: {response.status_code}\")\n",
    "    response.raise_for_status()\n",
    "    return BeautifulSoup(response.text).text\n",
    "\n",
    "print(parse_web_page('https://fmi.chnu.edu.ua/')[:255])\n",
    "print(parse_web_page('https://en.wikipedia.org/wiki/Web_scraping')[:255])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from the API\n",
    "\n",
    "Create a python script that performs basic request to API endpoint and saves that data to a JSON file `result.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api_url: https://api.github.com/\n",
      "status code: 200\n",
      "response.json(): {'current_user_url': 'https://api.github.com/user', 'current_user_authorizations_html_url': 'https://github.com/settings/connections/applications{/client_id}', 'authorizations_url': 'https://api.github.com/authorizations', 'code_search_url': 'https://api.github.com/search/code?q={query}{&page,per_page,sort,order}', 'commit_search_url': 'https://api.github.com/search/commits?q={query}{&page,per_page,sort,order}', 'emails_url': 'https://api.github.com/user/emails', 'emojis_url': 'https://api.github.com/emojis', 'events_url': 'https://api.github.com/events', 'feeds_url': 'https://api.github.com/feeds', 'followers_url': 'https://api.github.com/user/followers', 'following_url': 'https://api.github.com/user/following{/target}', 'gists_url': 'https://api.github.com/gists{/gist_id}', 'hub_url': 'https://api.github.com/hub', 'issue_search_url': 'https://api.github.com/search/issues?q={query}{&page,per_page,sort,order}', 'issues_url': 'https://api.github.com/issues', 'keys_url': 'https://api.github.com/user/keys', 'label_search_url': 'https://api.github.com/search/labels?q={query}&repository_id={repository_id}{&page,per_page}', 'notifications_url': 'https://api.github.com/notifications', 'organization_url': 'https://api.github.com/orgs/{org}', 'organization_repositories_url': 'https://api.github.com/orgs/{org}/repos{?type,page,per_page,sort}', 'organization_teams_url': 'https://api.github.com/orgs/{org}/teams', 'public_gists_url': 'https://api.github.com/gists/public', 'rate_limit_url': 'https://api.github.com/rate_limit', 'repository_url': 'https://api.github.com/repos/{owner}/{repo}', 'repository_search_url': 'https://api.github.com/search/repositories?q={query}{&page,per_page,sort,order}', 'current_user_repositories_url': 'https://api.github.com/user/repos{?type,page,per_page,sort}', 'starred_url': 'https://api.github.com/user/starred{/owner}{/repo}', 'starred_gists_url': 'https://api.github.com/gists/starred', 'topic_search_url': 'https://api.github.com/search/topics?q={query}{&page,per_page}', 'user_url': 'https://api.github.com/users/{user}', 'user_organizations_url': 'https://api.github.com/user/orgs', 'user_repositories_url': 'https://api.github.com/users/{user}/repos{?type,page,per_page,sort}', 'user_search_url': 'https://api.github.com/search/users?q={query}{&page,per_page,sort,order}'}\n",
      "api_url: https://fmi.chnu.edu.ua/\n",
      "status code: 200\n",
      "An error occurred during the call response.json().\n",
      "  Error: <class 'requests.exceptions.JSONDecodeError'>\n",
      "  Error message: Expecting value: line 1 column 1 (char 0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def parse_api(api_url):\n",
    "    \"\"\"\n",
    "    Fetch the data of the given API endpoint and save it to result.json.\n",
    "\n",
    "    Args:\n",
    "        api_url (str): The URL of the API endpoint.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "\n",
    "    Raises:\n",
    "        HTTPError: If the HTTP request returned an unsuccessful status code.\n",
    "    \"\"\"\n",
    "    print(f\"api_url: {api_url}\")\n",
    "    response = requests.get(api_url)\n",
    "    print(f\"status code: {response.status_code}\")\n",
    "    response.raise_for_status()\n",
    "\n",
    "    try:\n",
    "        response_json = response.json()\n",
    "    except Exception as error:\n",
    "        print(\"An error occurred during the call response.json().\\n\"\n",
    "              f\"  Error: {type(error)}\\n\"\n",
    "              f\"  Error message: {error}\\n\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"response.json(): {response_json}\")\n",
    "    \n",
    "    with open(\"result.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(response_json, file)\n",
    "\n",
    "    return None\n",
    "\n",
    "parse_api('https://api.github.com/')\n",
    "parse_api('https://fmi.chnu.edu.ua/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the json file\n",
    "\n",
    "Parse the `weather.json` file and return weather data for a specific date, that is given as a parameter. Return the data as an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'date': '2024-08-19', 'max_temperature': 30.0, 'min_temperature': 21.0, 'precipitation': 5.0, 'wind_speed': 10.0, 'humidity': 70, 'weather_description': 'Light rain'}]\n"
     ]
    }
   ],
   "source": [
    "def are_dates_same(date1: str, date2: str) -> bool:\n",
    "    if date1 == date2:\n",
    "        return True\n",
    "\n",
    "    return datetime.strptime(date1, \"%Y-%m-%d\") == datetime.strptime(date2, \"%Y-%m-%d\")\n",
    "\n",
    "def parse_json(date):\n",
    "    \"\"\"\n",
    "    Parse the data from weather.json file and return weather data for a given date.\n",
    "\n",
    "    Args:\n",
    "        date (str): The date for which we look up the weather.\n",
    "\n",
    "    Returns:\n",
    "        list: a list of weather data for a given date.\n",
    "    \"\"\"\n",
    "    weather_json_path = './resources/weather.json'\n",
    "    with open(weather_json_path, 'r', encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    result = []\n",
    "    try:\n",
    "        daily_weather = data['daily']\n",
    "        for day_info in daily_weather:\n",
    "            if are_dates_same(day_info['date'], date):\n",
    "                result.append(day_info)\n",
    "    except Exception as error:\n",
    "        print(\"An error occurred during parsing\\n\"\n",
    "              f\"  Error: {type(error)}\\n\"\n",
    "              f\"  Error message: {error}\\n\")\n",
    "    \n",
    "    return result\n",
    "    \n",
    "target_date = '2024-8-19'\n",
    "print(parse_json(target_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the csv file\n",
    "\n",
    "Parse the `weather.csv` file and return weather data for a specific date, that is given as a parameter. Return the data as an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_csv(date):\n",
    "    \"\"\"\n",
    "    Parse the data from weather.csv file and return weather data for a given date.\n",
    "\n",
    "    Args:\n",
    "        date (str): The date for which we look up the weather.\n",
    "\n",
    "    Returns:\n",
    "        list: a list of weather data for a given date.\n",
    "    \"\"\"\n",
    "    return None\n",
    "    \n",
    "target_date = '1997-5-22'\n",
    "print(parse_csv(target_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data\n",
    "\n",
    "Visualize the `weather.csv` data using matplotlib. Choose your own approach to data visualization. Save the results (as `.png`, `.webp` files etc., your choise) in this repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data():\n",
    "    \"\"\"\n",
    "    Parse the data from weather.csv file and visualize it using Matplotlib. Use more then one visualization. \n",
    "    Save the results in the repository.\n",
    "\n",
    "    Args:\n",
    "        None: None.\n",
    "\n",
    "    Returns:\n",
    "        None: None.\n",
    "    \"\"\"\n",
    "    return None\n",
    "\n",
    "visualize_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
